# Lecture 22. Efficiency

### 作业与项目的更新

- **本周实验**：截止日期为周二。
- **蚂蚁项目**：将于周五截止，但需要在周二前完成项目的第一和第二阶段。如果在周四之前提交整个项目，可获得提前提交的加分，建议尽量在周四前提交。
- **作业5**：已发布，截止日期是下周一。这份作业是即将到来的期中考试的一个很好的复习材料。
- **下周实验**：唯一必做的部分是完成作业5，实验中会有一些可选问题，可以帮助你为期中考试做额外的练习，但这些问题不是必做的。
- **匿名问卷**：这是填写第八周匿名问卷的最后机会，我们非常感谢您的反馈。

### 期中考试提醒

- **期中考试二**：将于下周三晚上7点（太平洋时间）举行，考试形式和风格与期中考试一相似，涵盖的内容截至上周五的讲座。
- **今天的讲座**（关于效率的内容）：不会出现在考试、作业或实验中，这只是一个本学期的选修话题，但在未来的 61B 课程中会深入学习效率相关的内容。因此，如果你将来会学习 61B，今天的讲座是一个很好的预习。

### 树递归与 Fibonacci 数列

在本节课中，我们介绍了如何使用树递归计算 Fibonacci 数列。树递归是指递归的每个分支可以生成多个递归调用，像一棵树一样展开。以下是 Fibonacci 数列的递归定义：
- **Fibonacci 序列**：`F(0) = 0`, `F(1) = 1`, 其余的值为前两个值的和，即 `F(n) = F(n-1) + F(n-2)`。

### 效率分析

在计算 Fibonacci 数列时，树递归的效率非常低，因为许多中间结果会被重复计算。例如，计算 `F(5)` 需要计算 `F(4)` 和 `F(3)`，而 `F(4)` 又需要再次计算 `F(3)`，这种重复计算导致时间复杂度呈指数增长。

通过**计算调用次数**，我们可以了解程序的执行效率。以下是 Fibonacci 递归的一个简单实现，并通过修饰器记录函数调用的次数：

#### 递归实现 Fibonacci 并计算调用次数：
```python
def fib(n):
    if n == 0 or n == 1:
        return n
    return fib(n - 2) + fib(n - 1)

def count_calls(f):
    def counted(n):
        counted.call_count += 1
        return f(n)
    counted.call_count = 0
    return counted

fib = count_calls(fib)

fib(5)
print(f"Fib(5) 被调用了 {fib.call_count} 次")  # 输出: Fib(5) 被调用了 15 次
```

随着 `n` 的增加，调用次数呈指数增长。例如，计算 `F(30)` 需要 2.69 百万次递归调用。显然，随着输入的增大，这种实现方式的效率非常低。

### 记忆化（Memoization）

为了提高效率，可以使用**记忆化**技术。记忆化是一种缓存技术，用于存储已经计算过的结果，从而避免重复计算。这可以极大地减少递归调用的次数，使得时间复杂度从指数级降低到线性级。

#### 记忆化实现 Fibonacci：
```python
def memo(f):
    cache = {}
    def memoized(n):
        if n not in cache:
            cache[n] = f(n)
        return cache[n]
    return memoized

@memo
def fib(n):
    if n == 0 or n == 1:
        return n
    return fib(n - 2) + fib(n - 1)

print(fib(30))  # 输出: 832040
```

通过记忆化，`F(30)` 的计算时间显著减少，因为每个值只会被计算一次，后续的计算直接从缓存中获取结果。

### 总结

- **树递归**：像 Fibonacci 数列这样的递归问题，可以用树状结构描述，效率低下的原因是重复计算。
- **计数调用次数**：通过装饰器记录函数调用次数，可以更好地理解程序的时间复杂度。
- **记忆化**：通过缓存已经计算过的值，记忆化技术可以极大提高递归程序的效率，从指数时间复杂度降低到线性时间复杂度。

本节课帮助我们理解了程序效率的基础知识，包括如何分析递归函数的性能，以及如何通过记忆化来优化递归计算。



### 记忆化（Memoization）与 Fibonacci 计算

#### 记忆化的基本思想

记忆化是一种通过缓存已计算结果来提高函数执行效率的技术。它适用于**纯函数**，即函数在相同输入下总是返回相同结果，且不依赖外部状态或产生副作用。

当使用记忆化技术时，函数的每次调用都会首先检查缓存是否已经存储了该输入的结果。如果已存储，则直接返回缓存的结果；如果没有存储，则计算结果并将其存储在缓存中，以备后续使用。

#### 记忆化 `fib` 函数的实现

```python
def memo(f):
    cache = {}  # 创建一个缓存字典
    def memoized(n):
        if n not in cache:  # 如果 n 不在缓存中
            cache[n] = f(n)  # 计算结果并存入缓存
        return cache[n]  # 返回缓存的结果
    return memoized
```

- **缓存字典（cache）**：存储函数的输入和对应的结果。输入作为键，结果作为值。
- **缓存检查**：在计算函数结果之前，先检查输入是否已经在缓存中。如果在缓存中，则直接返回缓存值；否则，计算并将结果存储在缓存中。

#### 使用记忆化加速 Fibonacci 计算

将 `fib` 函数与记忆化结合，实现快速计算 Fibonacci 数列。

```python
@memo
def fib(n):
    if n == 0 or n == 1:
        return n
    return fib(n - 2) + fib(n - 1)
```

- **基本情况**：当 `n` 为 0 或 1 时，直接返回 `n`。
- **递归计算**：对于其他情况，递归调用 `fib(n - 2)` 和 `fib(n - 1)`，并将结果相加。

#### 示例：
```python
print(fib(30))  # 输出: 832040，几乎瞬间计算出结果
```

通过记忆化，`fib(30)` 仅需计算每个 Fibonacci 数列项一次，而不会重复计算，从而显著减少了递归调用次数。

#### 调用次数分析

为了进一步分析调用次数，我们可以为 `fib` 函数添加计数功能，了解递归调用的实际次数。

```python
def count_calls(f):
    def counted(n):
        counted.call_count += 1
        return f(n)
    counted.call_count = 0
    return counted

fib = count_calls(fib)  # 包装 fib 函数以计数
```

在使用记忆化的情况下，计算 Fibonacci 数列时，**每个数值只会被计算一次**，随后如果再次需要该数值，将直接从缓存中读取。这使得 Fibonacci 数列的计算时间从指数级缩减为线性级。

#### 调用次数的分析结果

- **缓存命中**：当函数再次遇到相同的输入时，直接从缓存中读取，避免了递归调用。这大大减少了递归的深度和计算次数。
- **实际调用次数**：例如，计算 `fib(30)` 时，虽然 Fibonacci 数列的第 30 项需要递归调用很多次，但在使用记忆化后，`fib` 实际只被调用了 31 次（对应 0 到 30 之间的数值）。

### 高效的幂运算（Exponentiation）

除了 Fibonacci 计算，记忆化也可以应用于其他递归计算，例如幂运算。

#### 递归实现幂运算（效率较低）

传统的递归幂运算函数每次只减少 `n` 的值1，因此时间复杂度较高。

```python
def exp(b, n):
    if n == 0:
        return 1
    return b * exp(b, n - 1)
```

这种实现的时间复杂度为 O(n)，即每次递归只减少 `n` 的值1，因此倍数增加 `n` 时，计算时间也倍增。

#### 高效幂运算：使用平方加速（Exponentiation by Squaring）

我们可以通过**指数平方法**来提高幂运算的效率。在这种方法中，如果指数 `n` 是偶数，则将问题规模减半，通过平方减少计算次数；如果 `n` 是奇数，则递归调用并乘以基数 `b`。

```python
def fast_exp(b, n):
    if n == 0:
        return 1
    elif n % 2 == 0:
        half = fast_exp(b, n // 2)
        return half * half
    else:
        return b * fast_exp(b, n - 1)
```

- **偶数情况**：如果 `n` 是偶数，则递归调用 `fast_exp(b, n // 2)`，并将结果平方。
- **奇数情况**：如果 `n` 是奇数，则递归调用 `fast_exp(b, n - 1)`，并乘以基数 `b`。

#### 示例：
```python
print(fast_exp(2, 10))  # 输出: 1024
```

通过指数平方法，我们将幂运算的时间复杂度从 O(n) 降低到了 O(log n)，从而显著提高了运算效率。

### 总结

- **记忆化** 是一种通过缓存已计算结果来优化递归函数性能的技术，适用于纯函数，能大幅减少重复计算。
- **递归 Fibonacci** 在没有优化时性能较差，使用记忆化后，计算每个 Fibonacci 项的时间复杂度从 O(2^n) 降低到了 O(n)。
- **幂运算** 可以通过**指数平方法**优化，时间复杂度从 O(n) 降到 O(log n)。

这些优化技术在处理递归问题时极为重要，尤其是在需要处理大量重复计算的情况下。





### 指数运算的优化与时间复杂度

#### 递归实现的幂运算

在普通的递归幂运算中，每次递归调用只减少指数 `n` 的值 1，这导致运算的时间复杂度是线性的 O(n)，即输入的大小直接影响所需的计算时间。例如，计算 `2^100` 需要进行 100 次乘法操作。

#### 高效的幂运算：指数平方法

为了提高幂运算的效率，可以使用**指数平方法**，这种方法利用了以下事实：
- 当 `n` 为偶数时，`b^n = (b^(n//2))^2`。
- 当 `n` 为奇数时，`b^n = b * b^(n-1)`。

通过将 `n` 减半，指数平方法的时间复杂度降低到了 O(log n)，即输入 `n` 的大小每次减少一半，所需的乘法次数也相应减少。

#### 优化后的幂运算实现：

```python
def fast_exp(b, n):
    if n == 0:
        return 1
    elif n % 2 == 0:
        half = fast_exp(b, n // 2)
        return half * half  # 如果 n 是偶数，计算 (b^(n//2))^2
    else:
        return b * fast_exp(b, n - 1)  # 如果 n 是奇数，计算 b * b^(n-1)
```

在这种实现中，**每次将问题规模减半**，通过平方加速计算。

#### 示例：

```python
print(fast_exp(2, 10))  # 输出: 1024
print(fast_exp(2, 100))  # 输出: 非常快速的计算结果
```

#### 时间复杂度对比：

1. **线性时间（O(n)）**：
   - 普通递归方法每次减少 `n` 的值 1，因此计算 `2^n` 需要进行 `n` 次乘法操作。
   - 每当输入 `n` 加倍，运算时间也加倍，因此时间复杂度为 O(n)。

2. **对数时间（O(log n)）**：
   - 使用指数平方法，每次递归将 `n` 减半，因此时间复杂度为 O(log n)。
   - 当 `n` 加倍时，运算时间只增加一个常量倍数。

### 时间复杂度的概念

时间复杂度用于描述算法的性能，衡量输入规模（n）对运行时间的影响。以下是几种常见的时间复杂度：

1. **线性时间（O(n)）**：
   - 算法执行时间随着输入大小呈线性增长。例如，遍历一个长度为 `n` 的列表，时间复杂度为 O(n)。
   
2. **对数时间（O(log n)）**：
   - 每次递归调用将问题规模减半，时间复杂度为 O(log n)。指数平方法就是一个例子。

3. **二次时间（O(n^2)）**：
   - 对于每对输入进行比较，执行时间随输入大小呈平方增长。例如，嵌套的双重循环会产生 O(n^2) 的时间复杂度。
   - 示例：计算两个列表的重叠项。

```python
def overlap(a, b):
    count = 0
    for x in a:
        for y in b:
            if x == y:
                count += 1
    return count
```

- **示例**：计算 `[3, 5, 7, 6]` 和 `[4, 5, 6, 5]` 的重叠项，时间复杂度为 O(n^2)，即对每个 `a` 的元素，检查 `b` 中的所有元素。

4. **指数时间（O(2^n)）**：
   - 当问题的规模每次递归都成倍增加时，执行时间呈指数级增长。树递归是典型的例子，如未经优化的 Fibonacci 数列递归计算。

### 时间复杂度曲线的分析

- **线性增长**：时间复杂度为 O(n) 的函数，其时间随输入大小成正比增长。若输入大小翻倍，执行时间也翻倍。
- **对数增长**：时间复杂度为 O(log n) 的函数，其时间随输入大小增加而缓慢增长。每次输入翻倍时，执行时间仅增加一个常量倍数。
- **二次增长**：时间复杂度为 O(n^2) 的函数，其时间随输入大小呈平方增长。输入大小翻倍，执行时间会增长为原来的四倍。
- **指数增长**：时间复杂度为 O(2^n) 的函数，其时间随输入大小呈指数级增长，性能极差。

### 总结

通过优化算法的递归方式和时间复杂度，我们可以大幅提高算法的效率：
- **指数平方法** 将幂运算的时间复杂度从 O(n) 降低到了 O(log n)。
- 不同时间复杂度函数的性能在大规模输入下差异巨大，理解这些复杂度对于编写高效代码至关重要。

时间复杂度帮助我们理解算法在不同输入规模下的行为，为编写高效程序提供了理论依据。





### 常见的时间复杂度和增长类型

#### 1. 时间复杂度的概念

时间复杂度描述了算法的执行时间如何随输入大小（`n`）变化。理解时间复杂度对于分析算法的效率非常重要，不同的时间复杂度对程序处理大规模输入的能力有显著影响。

#### 2. 常见的增长类型

1. **指数增长（Exponential Growth, O(2^n)）**
   - 这种增长类型非常慢。递归函数（如未经优化的 Fibonacci 函数）如果没有记忆化（memoization），每增加一个输入都会显著增加计算量。例如计算 `fib(n)` 时，`fib(n+1)` 需要重新计算所有之前的值，导致大量重复计算。
   - **特点**：每次输入增加一，时间乘以一个常数（b）。
   - **公式**：`T(n+1) = a * b^(n+1)`。
   
2. **二次增长（Quadratic Growth, O(n^2)）**
   - 这种增长常见于双重循环中，每个元素都会与其他所有元素比较。例如，在两个列表之间计算重叠元素的数量时，每个列表中的元素都要与另一个列表中的所有元素进行比较。
   - **特点**：每次输入增加一，时间增加与输入大小成比例的量。
   - **公式**：`T(n+1) = a * (n+1)^2`。

3. **线性增长（Linear Growth, O(n)）**
   - 线性增长是非常常见的情况，例如遍历列表或数组时，每个元素只需处理一次，时间与输入大小成正比。
   - **特点**：每次输入增加一，时间增加一个常数。
   - **公式**：`T(n+1) = a * (n+1)`。

4. **对数增长（Logarithmic Growth, O(log n)）**
   - 对数增长非常高效，它的时间复杂度表示输入大小翻倍时，计算时间仅增加一个常数。例如，在二分搜索算法中，每次递归将输入大小减半，因此运行时间呈对数增长。
   - **特点**：输入大小翻倍，时间仅增加一个常数。
   - **公式**：`T(2n) = a * log(2n)`。

5. **常数增长（Constant Growth, O(1)）**
   - 常数时间表示无论输入大小如何变化，运行时间始终保持不变。一个典型例子是哈希表的查找操作，无论字典中有多少元素，查找一个键的时间始终相同。
   - **特点**：输入大小不影响运行时间。
   - **公式**：`T(n) = a`。

#### 3. 时间复杂度的比较

- **指数时间** 是最慢的，处理稍大的输入就会导致不可接受的计算时间。
- **二次时间** 虽然比指数时间好一些，但仍然随着输入大小成平方增长，适用于小规模输入。
- **线性时间** 是许多常见算法的复杂度，比如遍历和简单操作，处理较大规模输入仍然是可行的。
- **对数时间** 是非常理想的，它能够处理极大的输入规模，计算时间只会增加一个常数。
- **常数时间** 是最理想的，它的运行时间不受输入大小的影响。

#### 4. 如何通过优化改进时间复杂度

- **记忆化（Memoization）** 可以将一些递归函数的时间复杂度从**指数级**降低为**线性级**，通过缓存已经计算过的结果避免重复计算。
- **指数平方法（Exponentiation by Squaring）** 可以将指数运算的时间复杂度从 O(n) 降低到 O(log n)，每次将问题规模减半，大大提高了效率。

#### 5. 大 O 记号与增长分类

计算复杂度通常用**大 O 记号**（Big O Notation）或**大 θ 记号**（Big Theta Notation）来表示。这些符号用于表示算法的增长率，而不是具体的执行时间。

- **大 O 记号**：用于描述算法的上限，即最坏情况下的时间复杂度。
- **大 θ 记号**：用于描述算法的精确复杂度，即算法的增长率。

例如：
- 线性增长：`O(n)` 或 `Θ(n)`。
- 二次增长：`O(n^2)` 或 `Θ(n^2)`。
- 对数增长：`O(log n)` 或 `Θ(log n)`。

### 总结

理解不同的时间复杂度类型（如**指数时间**、**二次时间**、**线性时间**、**对数时间**）对于分析和优化算法非常重要。通过使用**记忆化**和**指数平方法**等技术，可以有效降低算法的时间复杂度，使程序在处理大规模输入时更加高效。





### 大 O 记号和大 Θ 记号的区别

在计算机科学中，我们经常使用 **大 O 记号（Big O Notation）** 和 **大 Θ 记号（Big Theta Notation）** 来描述算法的时间复杂度和增长行为。这些记号有助于我们理解程序在处理不同输入规模时的表现。

#### 大 Θ 记号（Big Theta Notation）
- **大 Θ** 描述了算法运行时间的**确切增长率**，即它既是算法的**上界**也是**下界**。
- **形式**：`Θ(f(n))` 表示算法在最坏、最好、平均情况下都表现为 `f(n)` 的增长。
  - 例如：`Θ(n^2)` 表示该算法的时间复杂度在所有情况下都是二次增长。

#### 大 O 记号（Big O Notation）
- **大 O** 主要用于描述算法的**上界**，即在最坏情况下，算法的执行时间不会超过某个量级。
- **形式**：`O(f(n))` 表示在最坏情况下，算法的时间复杂度不超过 `f(n)`。
  - 例如：`O(n^2)` 表示算法的最坏情况下表现为二次增长，但它可能在某些情况下表现得更好，比如 `O(n)` 或 `O(log n)`。

#### 常见增长类型及表示

1. **常数时间（Constant Time）**：
   - **大 Θ**：`Θ(1)` 
   - **大 O**：`O(1)`
   - **描述**：无论输入大小，操作的执行时间是固定的，例如哈希表查找。

2. **对数时间（Logarithmic Time）**：
   - **大 Θ**：`Θ(log n)` 
   - **大 O**：`O(log n)`
   - **描述**：输入每次增加一倍，时间只增加一个常量倍数。常见于二分查找算法。

3. **线性时间（Linear Time）**：
   - **大 Θ**：`Θ(n)` 
   - **大 O**：`O(n)`
   - **描述**：执行时间与输入规模成正比。常见于遍历列表。

4. **二次时间（Quadratic Time）**：
   - **大 Θ**：`Θ(n^2)` 
   - **大 O**：`O(n^2)`
   - **描述**：时间复杂度随输入大小平方增长。常见于嵌套循环。

5. **指数时间（Exponential Time）**：
   - **大 Θ**：`Θ(2^n)` 
   - **大 O**：`O(2^n)`
   - **描述**：时间复杂度呈指数增长，通常效率非常低。

### 空间复杂度和内存管理

空间复杂度描述了程序执行时所消耗的内存资源。除了时间复杂度外，了解程序在运行时占用的内存（即**栈帧数量**）也很重要。

#### 栈帧（Frames）和空间消耗

每次函数调用都会创建一个新的栈帧，这个栈帧存储了函数的局部变量、参数以及其他相关数据。在递归调用中，函数会嵌套调用，导致多个栈帧被占用，直到所有递归函数返回为止。

- **栈帧的空间**：栈帧占用内存，当递归调用层数较多时，会占用大量内存。计算 Fibonacci 数列时，每层递归都创建新的栈帧，直到递归完全展开。

#### 示例：计算 Fibonacci 数列时的栈帧

例如，在递归计算 Fibonacci 数列时，每个递归调用都创建一个栈帧。栈帧的最大数量与递归深度相关。

通过定义一个统计栈帧的函数，我们可以测量 Fibonacci 函数在执行过程中打开的栈帧数量：

```python
def count_frames(f):
    def counted(n):
        counted.open_count += 1
        counted.max_count = max(counted.max_count, counted.open_count)
        result = f(n)
        counted.open_count -= 1
        return result
    counted.open_count = 0
    counted.max_count = 0
    return counted
```

我们可以使用该函数包装 Fibonacci 函数，测量执行时最大打开的栈帧数量：

```python
@count_frames
def fib(n):
    if n == 0 or n == 1:
        return n
    return fib(n - 1) + fib(n - 2)

fib(20)
print(fib.max_count)  # 输出: 20，表示最多打开了 20 个栈帧
```

- **结果分析**：在递归计算 Fibonacci(20) 时，最多打开了 20 个栈帧，这意味着递归深度达到了 20 层。

### 内存管理和垃圾回收

Python 通过自动垃圾回收（Garbage Collection）机制回收不再使用的内存。当递归函数返回时，Python 会自动清除已返回的栈帧，以便释放内存资源。

#### 空间复杂度的优化

在递归算法中，空间消耗主要由栈帧决定。优化空间复杂度的常见方法包括：
1. **尾递归优化**：某些编程语言支持尾递归优化，减少栈帧的占用。
2. **迭代替代递归**：通过将递归改为迭代，可以避免深度递归导致的栈溢出问题。

### 总结

- **大 O 记号**和**大 Θ 记号**是描述算法时间复杂度的工具，大 O 描述上界，而大 Θ 描述准确的增长率。
- 递归算法的空间复杂度由栈帧数量决定。理解栈帧的管理对于分析递归算法的内存占用至关重要。
- 通过自动垃圾回收机制，Python 可以回收已完成函数的栈帧，从而优化内存使用。





